services:
  # MongoDB Database
  mongodb:
    image: mongo:8.0
    container_name: architecture-builder-mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    environment:
      - MONGO_INITDB_DATABASE=architecture_builder
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - architecture-network

  # FastAPI Backend
  backend:
    container_name: architecture-builder-backend
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./backend/app:/app/app
    environment:
      # MongoDB Configuration
      - MONGODB_URL=mongodb://mongodb:27017
      - MONGODB_DB_NAME=architecture_builder
      
      # JWT Configuration
      - JWT_SECRET_KEY=${JWT_SECRET_KEY:-your-super-secret-key-change-in-production}
      - JWT_ALGORITHM=${JWT_ALGORITHM:-HS256}
      - ACCESS_TOKEN_EXPIRE_MINUTES=${ACCESS_TOKEN_EXPIRE_MINUTES:-30}
      
      # Application
      - DEBUG=${DEBUG:-true}
      - APP_NAME=${APP_NAME:-Architecture Builder API}
      - APP_VERSION=${APP_VERSION:-1.0.0}
      
      # CORS
      - CORS_ORIGINS=${CORS_ORIGINS:-["http://localhost:4200","http://frontend:4200"]}
      
      # =============================================================================
      # LLM Configuration
      # =============================================================================
      
      # Provider Selection: openai | azure | ollama
      - LLM_PROVIDER=${LLM_PROVIDER:-openai}
      
      # OpenAI Configuration (only set if using OpenAI provider)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_API_URL=${OPENAI_API_URL:-https://api.openai.com/v1}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-4o-mini}
      
      # Azure OpenAI Configuration
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY:-}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT:-https://chat-ai.cisco.com}
      - AZURE_OPENAI_API_VERSION=${AZURE_OPENAI_API_VERSION:-2023-08-01-preview}
      - AZURE_OPENAI_DEPLOYMENT=${AZURE_OPENAI_DEPLOYMENT:-gpt-4.1}
      - AZURE_OPENAI_APP_KEY=${AZURE_OPENAI_APP_KEY:-}
      - AZURE_USER_ID=${AZURE_USER_ID:-}
      
      # OAuth2 Token Authentication (for Cisco Azure)
      - TOKEN_URL=${TOKEN_URL:-}
      - CLIENT_ID=${CLIENT_ID:-}
      - CLIENT_SECRET=${CLIENT_SECRET:-}
      - ENABLE_TOKEN_CACHING=${ENABLE_TOKEN_CACHING:-true}
      - TOKEN_CACHE_TTL=${TOKEN_CACHE_TTL:-3300}
      
      # Ollama Configuration (Local LLM)
      - OLLAMA_BASE_URL=${OLLAMA_BASE_URL:-http://host.docker.internal:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3.2}
      
      # LLM Parameters
      - LLM_TEMPERATURE=${LLM_TEMPERATURE:-0.7}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-4096}
      - LLM_MAX_RETRIES=${LLM_MAX_RETRIES:-3}
      - LLM_TIMEOUT=${LLM_TIMEOUT:-120}
      
    depends_on:
      mongodb:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - architecture-network
    # For Ollama access on host machine
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # Angular Frontend
  frontend:
    container_name: architecture-builder-frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "4200:4200"
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
      - ./frontend/samples:/app/samples
      - /app/node_modules
    environment:
      - NODE_ENV=development
      - API_URL=http://backend:8000
    depends_on:
      - backend
    networks:
      - architecture-network

  # Optional: Ollama for local LLM (uncomment to use)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: architecture-builder-ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   networks:
  #     - architecture-network
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]

volumes:
  mongodb_data:
    driver: local
  # ollama_data:
  #   driver: local

networks:
  architecture-network:
    driver: bridge
